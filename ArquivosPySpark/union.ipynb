{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edb714f8-ada7-4417-948a-f098cb32d9cc",
     "showTitle": true,
     "title": "Criação do DataFrame 01"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- funcao: string (nullable = true)\n |-- estado: string (nullable = true)\n |-- salario: long (nullable = true)\n |-- idade: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------+----------+------+-------+-----+-----+\n|nome   |funcao    |estado|salario|idade|bonus|\n+-------+----------+------+-------+-----+-----+\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Roberta|Vendedora |BA    |86000  |56   |20000|\n|Nina   |Médica    |RJ    |81000  |30   |23000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n+-------+----------+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "dados = [(\"Gabriel\",\"Analista\",\"RJ\",90000,34,10000), \\\n",
    "    (\"Roberta\",\"Vendedora\",\"BA\",86000,56,20000), \\\n",
    "    (\"Nina\",\"Médica\",\"RJ\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Enfermeira\",\"MA\",90000,24,23000) \\\n",
    "  ]\n",
    "\n",
    "schema= [\"nome\",\"funcao\",\"estado\",\"salario\",\"idade\",\"bonus\"]\n",
    "df = spark.createDataFrame(data = dados, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55dcfa4f-863d-4306-bce2-d7e1500a9ea8",
     "showTitle": true,
     "title": "Criação do DataFrame 02"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- funcao: string (nullable = true)\n |-- estado: string (nullable = true)\n |-- salario: long (nullable = true)\n |-- idade: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------+----------+------+-------+-----+-----+\n|nome   |funcao    |estado|salario|idade|bonus|\n+-------+----------+------+-------+-----+-----+\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Nina   |Médica    |RJ    |79000  |53   |15000|\n|Roberta|Vendedora |BA    |80000  |25   |18000|\n|Claudio|Militar   |BH    |91000  |50   |21000|\n+-------+----------+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "dados = [(\"Gabriel\",\"Analista\",\"RJ\",90000,34,10000), \\\n",
    "    (\"Maria\",\"Enfermeira\",\"MA\",90000,24,23000), \\\n",
    "    (\"Nina\",\"Médica\",\"RJ\",79000,53,15000), \\\n",
    "    (\"Roberta\",\"Vendedora\",\"BA\",80000,25,18000), \\\n",
    "    (\"Claudio\",\"Militar\",\"BH\",91000,50,21000) \\\n",
    "  ]\n",
    "columns2= [\"nome\",\"funcao\",\"estado\",\"salario\",\"idade\",\"bonus\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data = dados, schema = schema)\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7277ae73-ed94-43d6-b05c-45c1c723404d",
     "showTitle": true,
     "title": "Explicação"
    }
   },
   "source": [
    "## SQL \n",
    "    * Union - EXCLUI DUPLICATADAS NO SQL\n",
    "    * Union ALL - NÃO EXCLUI DUPLICATADAS NO SQL\n",
    "\n",
    "  * Link Documentacão: https://learn.microsoft.com/pt-br/sql/t-sql/language-elements/set-operators-union-transact-sql?view=sql-server-ver16\n",
    "\n",
    "## PYSPARK \n",
    "    * Union - NÃO EXCLUI DUPLICATADAS NO PYSPARK\n",
    "    * Union ALL - FOI DESCONTINUADO NA VERSÃO 2 DO SPARK\n",
    "\n",
    "  * Link Documentação: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.union.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaa41aee-d200-4861-8878-b886257262aa",
     "showTitle": true,
     "title": "Union All - Unificamos os dois dataframes sem remover dados duplicados"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- funcao: string (nullable = true)\n |-- estado: string (nullable = true)\n |-- salario: long (nullable = true)\n |-- idade: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------+----------+------+-------+-----+-----+\n|nome   |funcao    |estado|salario|idade|bonus|\n+-------+----------+------+-------+-----+-----+\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Roberta|Vendedora |BA    |86000  |56   |20000|\n|Nina   |Médica    |RJ    |81000  |30   |23000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Nina   |Médica    |RJ    |79000  |53   |15000|\n|Roberta|Vendedora |BA    |80000  |25   |18000|\n|Claudio|Militar   |BH    |91000  |50   |21000|\n+-------+----------+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df3 = df.union(df2)\n",
    "\n",
    "df3.printSchema()\n",
    "\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90cfadea-e7d9-4c72-82c2-738a9f85a577",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+-----+-----+\n|nome   |funcao    |estado|salario|idade|bonus|\n+-------+----------+------+-------+-----+-----+\n|Claudio|Militar   |BH    |91000  |50   |21000|\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Nina   |Médica    |RJ    |79000  |53   |15000|\n|Nina   |Médica    |RJ    |81000  |30   |23000|\n|Roberta|Vendedora |BA    |80000  |25   |18000|\n|Roberta|Vendedora |BA    |86000  |56   |20000|\n+-------+----------+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df3.orderBy([\"nome\",\"funcao\",\"estado\",\"salario\",\"idade\",\"bonus\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37552c8c-900d-4a02-b7e7-f2bbcee9244d",
     "showTitle": true,
     "title": "Union - Unificamos os dois dataframes REMOVENDO dados duplicados"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- funcao: string (nullable = true)\n |-- estado: string (nullable = true)\n |-- salario: long (nullable = true)\n |-- idade: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------+----------+------+-------+-----+-----+\n|nome   |funcao    |estado|salario|idade|bonus|\n+-------+----------+------+-------+-----+-----+\n|Claudio|Militar   |BH    |91000  |50   |21000|\n|Gabriel|Analista  |RJ    |90000  |34   |10000|\n|Maria  |Enfermeira|MA    |90000  |24   |23000|\n|Nina   |Médica    |RJ    |79000  |53   |15000|\n|Nina   |Médica    |RJ    |81000  |30   |23000|\n|Roberta|Vendedora |BA    |80000  |25   |18000|\n|Roberta|Vendedora |BA    |86000  |56   |20000|\n+-------+----------+------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df3 = df.union(df2).distinct()\n",
    "\n",
    "df3.printSchema()\n",
    "\n",
    "df3.orderBy([\"nome\",\"funcao\",\"estado\",\"salario\",\"idade\",\"bonus\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aaed56d-d953-456a-bfad-8059ea0dd2ae",
     "showTitle": true,
     "title": "UnionByName - Com Colunas Inexistentes usando o parâmetro \"allowMissingColumns\""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- idade: string (nullable = true)\n |-- sexo: string (nullable = true)\n |-- telefone: string (nullable = true)\n\n+-------+-----+----+-----------+\n|nome   |idade|sexo|telefone   |\n+-------+-----+----+-----------+\n|maria  |28   |f   |null       |\n|gabriel|null |m   |21987654321|\n+-------+-----+----+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = spark.createDataFrame([['maria','28','f']] , ['nome','idade','sexo'])\n",
    "\n",
    "df2 =  spark.createDataFrame([['gabriel', '21987654321','m']] , ['nome', 'telefone','sexo'])\n",
    "\n",
    "df3 = df1.unionByName(df2, allowMissingColumns=True)\n",
    "\n",
    "df3.printSchema()\n",
    "\n",
    "df3.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60871043-c3af-4e09-9ab2-195774f9cacd",
     "showTitle": true,
     "title": "UnionByName - Com Colunas Em Ordens Diferentes"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- nome: string (nullable = true)\n |-- idade: string (nullable = true)\n |-- sexo: string (nullable = true)\n\n+-------+-----+----+\n|nome   |idade|sexo|\n+-------+-----+----+\n|maria  |28   |f   |\n|gabriel|21   |m   |\n+-------+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = spark.createDataFrame([['maria','28','f']] , ['nome','idade','sexo'])\n",
    "\n",
    "df2 =  spark.createDataFrame([['gabriel','m' ,'21']] , ['nome', 'sexo','idade'])\n",
    "\n",
    "df3 = df1.unionByName(df2)\n",
    "\n",
    "df3.printSchema()\n",
    "\n",
    "df3.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "union",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
